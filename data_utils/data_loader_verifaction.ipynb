{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Loader Function:\n",
    "\n",
    "# Group Activity Data Loader:\n",
    "# \t1. Can return a full image of target frame with its group label (frame, tensor(8)) *needed for B1*. \n",
    "# \t2. Can return a all player crops of the target frame with its group label all player have same label  ( (12, crop frame), tensor(1,8)) *needed for B3 step B, C*.\n",
    "# \t3. Can return a full clip with each frame dir with its group label (all the same) ((9, frame) , tensor(9,8)) *needed for B4*.\n",
    "#   4. Can return a full clip with all player crop with its group label (all the same) ((12, 9, crop frame), tensor(9,8)) *needed for B5, B6, B7, B8*.\n",
    "\n",
    "#  Person Activity Data Loader:\n",
    "# \t1. Can return crop of player image frames in independent way (crop frame , tensor(9)) *needed for B3 step A , B6*.\n",
    "# \t2. Can return crop of player in the same clip (12 , 9, crop frame) , (tensor(12, 9, 9)) *needed for B5, B7*.\n",
    "\t\n",
    "# Note:\n",
    "# 1.  frame and crop frame means all image dim (C, H, W).\n",
    "# 2.  Group Activity Data Loader Case 1 and 2 only utilize target frame  of each clip\n",
    "\n",
    "################################################################################################################################\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "PROJECT_ROOT= \"/teamspace/studios/this_studio/Group-Activity-Recognition\"\n",
    "sys.path.append(os.path.abspath(PROJECT_ROOT))\n",
    "from data_loader import Person_Activity_DataSet, Group_Activity_DataSet\n",
    "\n",
    "dataset_root = \"/teamspace/studios/this_studio/Group-Activity-Recognition/data\"\n",
    "annot_path =   f\"{dataset_root}/annot_all.pkl\"\n",
    "videos_path =  f\"{dataset_root}/videos\"\n",
    "\n",
    "people_activity_clases = [\"Waiting\", \"Setting\", \"Digging\", \"Falling\" ,\"Spiking\"\t, \"Blocking\", \"Jumping\"\t, \"Moving\", \"Standing\"]\n",
    "person_activity_labels  = {class_name.lower():i for i, class_name in enumerate(people_activity_clases)}\n",
    "\n",
    "group_activity_clases = [\"r_set\", \"r_spike\" , \"r-pass\", \"r_winpoint\", \"l_winpoint\", \"l-pass\", \"l-spike\", \"l_set\"]\n",
    "group_activity_labels  = {class_name:i for i, class_name in enumerate(group_activity_clases)}\n",
    "\n",
    "train_spilt = [1, 3, 6, 7, 10, 13, 15, 16, 18, 22, 23, 31, 32, 36, 38, 39, 40, 41, 42, 48, 50, 52, 53, 54]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test people activity data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Can return crop of player image frames in independent way (crop frame , tensor(9)) *needed for B3 step A , B6*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(224, 224),  \n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "data_loader = Person_Activity_DataSet(videos_path, annot_path, split=train_spilt, seq=False, labels=person_activity_labels, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame , label = data_loader[0]\n",
    "\n",
    "label.shape # (,9) class of person activity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.shape # (C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame , label = data_loader[50]\n",
    "\n",
    "label_idex = label.argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(frame.permute(1,2,0))  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  # Optional: to hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame , label = data_loader[450]\n",
    "\n",
    "label_idex = label.argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(frame.permute(1,2,0))  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  # Optional: to hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame , label = data_loader[120]\n",
    "\n",
    "label_idex = label.argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(frame.permute(1,2,0))  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  # Optional: to hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame , label = data_loader[800]\n",
    "\n",
    "label_idex = label.argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(frame.permute(1,2,0))  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  # Optional: to hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Can return crop of player in the same clip (12 , 9, crop frame) , (tensor(12, 9, 9)) *needed for B5, B7*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms = v2.Compose([\n",
    "#                 v2.ToPILImage(),    \n",
    "#                 v2.Resize((28, 28)),\n",
    "#                 v2.ToImage(), \n",
    "#                 v2.ToDtype(torch.float32, scale=True)\n",
    "#             ])\n",
    "transforms = A.Compose([\n",
    "    A.Resize(224, 224),  \n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "data_loader = Person_Activity_DataSet(videos_path, annot_path, split=train_spilt, seq=True, labels=person_activity_labels, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip, label = data_loader[100]\n",
    "\n",
    "label.shape # (12 player , 9 frame , label of 9 class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip.shape #  (12 player, 9 frame, C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = label[0, 0].argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) # frist player  - first frame\n",
    "plt.imshow(clip[0, 0].permute(1, 2, 0).numpy())  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  # Optional: to hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = label[0, 2].argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) # frist player  - Thrid frame\n",
    "plt.imshow(clip[0, 2].permute(1, 2, 0).numpy())  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = label[0, 4].argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(clip[0, 4].permute(1, 2, 0).numpy())  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = label[0, 6].argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(clip[0, 6].permute(1, 2, 0).numpy())  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = label[0, 8].argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) # frist player  - last frame\n",
    "plt.imshow(clip[0, 8].permute(1, 2, 0).numpy())  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = label[8, 2].argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(clip[1, 0].permute(1, 2, 0).numpy())  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = label[8, 4].argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(clip[1, 4].permute(1, 2, 0).numpy())  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = label[8, 6].argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(clip[1, 6].permute(1, 2, 0).numpy())  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = label[8, 8].argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) # second player  - last frame\n",
    "plt.imshow(clip[1, 8].permute(1, 2, 0).numpy())  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Group Activity data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Can return a full image of target frame with its group label (frame, tensor(8)) *needed for B1*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(224, 224),  \n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "data_loader = Group_Activity_DataSet(videos_path, annot_path, split=train_spilt, crops=False , seq=False, labels=group_activity_labels, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_loader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame , label = data_loader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label.shape) # (,8)\n",
    "label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.shape # (C, H , W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = data_loader[0][1].argmax().item()\n",
    "print(f\"{group_activity_clases[index]}\")\n",
    "\n",
    "plt.imshow(data_loader[0][0].permute(1,2,0)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = data_loader[152][1].argmax().item()\n",
    "print(f\"{group_activity_clases[index]}\")\n",
    "\n",
    "plt.imshow(data_loader[152][0].permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Can return a all player crops of the target frame with its group label (all player have same label)  ( (12, crop frame), tensor(1,8)) *needed for B3 step B, C*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(224, 224),  \n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "data_loader= Group_Activity_DataSet(videos_path, annot_path, split=train_spilt, crops=True , seq=False, labels=group_activity_labels, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_loader) # the differents between case 1 and 2 the input consist of 12 bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_crops, label = data_loader[152]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label.shape) # (,8)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_crops.shape # (12, C, H, W) ---> 12 bbox of the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame_crops[0].permute(1,2,0))  # first bbox of the fraem\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame_crops[11].permute(1,2,0))  # last bbox of the frame\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can return a full clip with each frame dir with its group label (all the same) ((9, frame) , tensor(9,8)) *needed for B4*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(224, 224),  \n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "data_loader = Group_Activity_DataSet(videos_path, annot_path, split=train_spilt, crops=False , seq=True, labels=group_activity_labels, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip , label = data_loader[100] \n",
    "clip.shape # (9 frames, C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_activity_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) # First frame of the clip\n",
    "plt.imshow(clip[0].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) # second frame of the clip\n",
    "plt.imshow(clip[1].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(clip[2].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(clip[3].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(clip[4].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(clip[5].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(clip[6].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(clip[7].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) # Last frame of the clip\n",
    "plt.imshow(clip[8].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Can return a full clip with all player crop with its group label (all the same) ((12, 9, crop frame), tensor(9,8)) *needed for B5, B6, B7, B8*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(224, 224),  \n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "data_loader = Group_Activity_DataSet(videos_path, annot_path, split=train_spilt, crops=True , seq=True, labels=group_activity_labels, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip, label = data_loader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.shape # (9, 8) each frame has the same label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip.shape # (12, 9, C, H, W) 12 player , 9 frames, Channls , High, Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) # first player - first frame\n",
    "plt.imshow(clip[0][0].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) # first player - second frame\n",
    "plt.imshow(clip[0][1].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) # first player - thrid frame\n",
    "plt.imshow(clip[0][2].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) # first player - fourth frame\n",
    "plt.imshow(clip[0][3].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) # first player - fifth frame\n",
    "plt.imshow(clip[0][4].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) # first player - sixth frame\n",
    "plt.imshow(clip[0][5].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) # first player - seventh frame\n",
    "plt.imshow(clip[0][6].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) # first player - eighth frame\n",
    "plt.imshow(clip[0][7].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) # first player - last frame\n",
    "plt.imshow(clip[0][8].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
