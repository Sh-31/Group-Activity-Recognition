{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Loader Function:\n",
    "\n",
    "# Group Activity Data Loader:\n",
    "# \t1. Can return a full image of target frame with its group label (frame, tensor(8)) *needed for B1*. \n",
    "# \t2. Can return a all player crops of the target frame with its group label all player have same label  ( (12, crop frame), tensor(1,8)) *needed for B3 step B, C*.\n",
    "# \t3. Can return a full clip with each frame dir with its group label (all the same) ((9, frame) , tensor(9,8)) *needed for B4*.\n",
    "#   4. Can return a full clip with all player crop with its group label (all the same) ((12, 9, crop frame), tensor(9,8)) *needed for B5, B6, B7*.\n",
    "\n",
    "#  Person Activity Data Loader:\n",
    "# \t1. Can return crop of player image frames in independent way (crop frame , tensor(9)) *needed for B3 step A , B6*.\n",
    "# \t2. Can return crop of player in the same clip (12 , 9, crop frame) , (tensor(12, 9, 9)) *needed for B5, B7*.\n",
    "\n",
    "# Hierarchical Group Activity Data Loader:    \n",
    "#   1. Can return crop of player in the same clip, each players label and group label of the clip ( (12, 9, crop frame), (12, 9, 9), (9,8) ) *needed for B9*.\t\n",
    "\n",
    "# Note:\n",
    "# 1.  Frame and crop frame means all image dim (C, H, W).\n",
    "# 2.  The Sort flag (sort the player by the tracer id) *needed for B8*.\n",
    "\n",
    "################################################################################################################################\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "PROJECT_ROOT= \"/teamspace/studios/this_studio/Group-Activity-Recognition\"\n",
    "sys.path.append(os.path.abspath(PROJECT_ROOT))\n",
    "from data_loader import Person_Activity_DataSet, Group_Activity_DataSet, Hierarchical_Group_Activity_DataSet\n",
    "\n",
    "dataset_root = \"/teamspace/studios/this_studio/Group-Activity-Recognition/data\"\n",
    "annot_path =   f\"{dataset_root}/annot_all.pkl\"\n",
    "videos_path =  f\"{dataset_root}/videos\"\n",
    "\n",
    "people_activity_clases = [\"Waiting\", \"Setting\", \"Digging\", \"Falling\" ,\"Spiking\"\t, \"Blocking\", \"Jumping\"\t, \"Moving\", \"Standing\"]\n",
    "person_activity_labels  = {class_name.lower():i for i, class_name in enumerate(people_activity_clases)}\n",
    "\n",
    "group_activity_clases = [\"r_set\", \"r_spike\" , \"r-pass\", \"r_winpoint\", \"l_winpoint\", \"l-pass\", \"l-spike\", \"l_set\"]\n",
    "group_activity_labels  = {class_name:i for i, class_name in enumerate(group_activity_clases)}\n",
    "\n",
    "activities_labels = {\"person\": person_activity_labels, \"group\": group_activity_labels}\n",
    "\n",
    "train_spilt = [1, 3, 6, 7, 10, 13, 15, 16, 18, 22, 23, 31, 32, 36, 38, 39, 40, 41, 42, 48, 50, 52, 53, 54]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test people activity data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Can return crop of player image frames in independent way (crop frame , tensor(9)) *needed for B3 step A , B6*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(224, 224),  \n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "data_loader = Person_Activity_DataSet(videos_path, annot_path, split=train_spilt, seq=False, labels=person_activity_labels, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame , label = data_loader[0]\n",
    "\n",
    "label.shape # (,9) class of person activity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.shape # (C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame , label = data_loader[50]\n",
    "\n",
    "label_idex = label.argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(frame.permute(1,2,0))  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  # Optional: to hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame , label = data_loader[450]\n",
    "\n",
    "label_idex = label.argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(frame.permute(1,2,0))  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  # Optional: to hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame , label = data_loader[120]\n",
    "\n",
    "label_idex = label.argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(frame.permute(1,2,0))  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  # Optional: to hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame , label = data_loader[800]\n",
    "\n",
    "label_idex = label.argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(frame.permute(1,2,0))  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  # Optional: to hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Can return crop of player in the same clip (12 , 9, crop frame) , (tensor(12, 9, 9)) *needed for B5, B7*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(224, 224),  \n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "data_loader = Person_Activity_DataSet(videos_path, annot_path, split=train_spilt, seq=True, labels=person_activity_labels, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip, label = data_loader[100]\n",
    "\n",
    "label.shape # (12 player , 9 frame , label of 9 class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip.shape #  (12 player, 9 frame, C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = label[0, 0].argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) # frist player  - first frame\n",
    "plt.imshow(clip[0, 0].permute(1, 2, 0).numpy())  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  # Optional: to hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = label[0, 2].argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) # frist player  - Thrid frame\n",
    "plt.imshow(clip[0, 2].permute(1, 2, 0).numpy())  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = label[0, 4].argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(clip[0, 4].permute(1, 2, 0).numpy())  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = label[0, 6].argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(clip[0, 6].permute(1, 2, 0).numpy())  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = label[0, 8].argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) # frist player  - last frame\n",
    "plt.imshow(clip[0, 8].permute(1, 2, 0).numpy())  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = label[8, 2].argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(clip[1, 0].permute(1, 2, 0).numpy())  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = label[8, 4].argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(clip[1, 4].permute(1, 2, 0).numpy())  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = label[8, 6].argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(clip[1, 6].permute(1, 2, 0).numpy())  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = label[8, 8].argmax().item()\n",
    "print(f\"{people_activity_clases[label_idex]}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2)) # second player  - last frame\n",
    "plt.imshow(clip[1, 8].permute(1, 2, 0).numpy())  # Converts from (C, H, W) to (H, W, C)\n",
    "plt.axis('off')  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test group activity data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Can return a full image of target frame with its group label (frame, tensor(8)) *needed for B1*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(224, 224),  \n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "data_loader = Group_Activity_DataSet(videos_path, annot_path, split=train_spilt, crops=False , seq=False, labels=group_activity_labels, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_loader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame , label = data_loader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label.shape) # (,8)\n",
    "label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.shape # (C, H , W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = data_loader[0][1].argmax().item()\n",
    "print(f\"{group_activity_clases[index]}\")\n",
    "\n",
    "plt.imshow(data_loader[0][0].permute(1,2,0)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = data_loader[152][1].argmax().item()\n",
    "print(f\"{group_activity_clases[index]}\")\n",
    "\n",
    "plt.imshow(data_loader[152][0].permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Can return a all player crops of the target frame with its group label (all player have same label)  ( (12, crop frame), tensor(1,8)) *needed for B3 step B, C*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(224, 224),  \n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "data_loader= Group_Activity_DataSet(videos_path, annot_path, split=train_spilt, crops=True , seq=False, labels=group_activity_labels, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_loader) # the differents between case 1 and 2 the input consist of 12 bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_crops, label = data_loader[152]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label.shape) # (,8)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_crops.shape # (12, C, H, W) ---> 12 bbox of the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame_crops[0].permute(1,2,0))  # first bbox of the fraem\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame_crops[11].permute(1,2,0))  # last bbox of the frame\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can return a full clip with each frame dir with its group label (all the same) ((9, frame) , tensor(9,8)) *needed for B4*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(224, 224),  \n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "data_loader = Group_Activity_DataSet(videos_path, annot_path, split=train_spilt, crops=False , seq=True, labels=group_activity_labels, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip , label = data_loader[100] \n",
    "clip.shape # (9 frames, C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_activity_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) # First frame of the clip\n",
    "plt.imshow(clip[0].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) # second frame of the clip\n",
    "plt.imshow(clip[1].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(clip[2].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(clip[3].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(clip[4].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(clip[5].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(clip[6].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(clip[7].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2)) # Last frame of the clip\n",
    "plt.imshow(clip[8].permute(1, 2, 0).numpy())  \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Can return a full clip with all player crop with its group label (all the same) ((12, 9, crop frame), tensor(9,8)) *needed for B5, B6, B7*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(224, 224),  \n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "data_loader = Group_Activity_DataSet(videos_path, annot_path, split=train_spilt, crops=True , seq=True, labels=group_activity_labels, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip, label = data_loader[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.shape # (9, 8) each frame has the same label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip.shape # (12, 9, C, H, W) 12 player , 9 frames, Channls , High, Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame0 = clip[:, 0, : , : , :] \n",
    "\n",
    "titles = [f\"Player {i+1}\" for i in range(12)]  \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, player in enumerate(frame0):\n",
    "    plt.subplot(2, 6, i + 1)\n",
    "    plt.imshow(player.permute(1, 2, 0).numpy())\n",
    "    plt.title(titles[i])  \n",
    "    plt.axis('off')      \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1 = clip[:, 1, : , : , :] \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, player in enumerate(frame1):\n",
    "    plt.subplot(2, 6, i + 1)\n",
    "    plt.imshow(player.permute(1, 2, 0).numpy())\n",
    "    plt.title(titles[i])  \n",
    "    plt.axis('off')      \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2 = clip[:, 2, : , : , :] \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, player in enumerate(frame2):\n",
    "    plt.subplot(2, 6, i + 1)\n",
    "    plt.imshow(player.permute(1, 2, 0).numpy())\n",
    "    plt.title(titles[i])  \n",
    "    plt.axis('off')      \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3 = clip[:, 3, : , : , :] \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, player in enumerate(frame3):\n",
    "    plt.subplot(2, 6, i + 1)\n",
    "    plt.imshow(player.permute(1, 2, 0).numpy())\n",
    "    plt.title(titles[i])  \n",
    "    plt.axis('off')      \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame4 = clip[:, 4, : , : , :] \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, player in enumerate(frame4):\n",
    "    plt.subplot(2, 6, i + 1)\n",
    "    plt.imshow(player.permute(1, 2, 0).numpy())\n",
    "    plt.title(titles[i])  \n",
    "    plt.axis('off')      \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame5 = clip[:, 5, : , : , :] \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, player in enumerate(frame5):\n",
    "    plt.subplot(2, 6, i + 1)\n",
    "    plt.imshow(player.permute(1, 2, 0).numpy())\n",
    "    plt.title(titles[i])  \n",
    "    plt.axis('off')      \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame6 = clip[:, 6, : , : , :] \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, player in enumerate(frame6):\n",
    "    plt.subplot(2, 6, i + 1)\n",
    "    plt.imshow(player.permute(1, 2, 0).numpy())\n",
    "    plt.title(titles[i])  \n",
    "    plt.axis('off')      \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame7 = clip[:, 7, : , : , :] \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, player in enumerate(frame7):\n",
    "    plt.subplot(2, 6, i + 1)\n",
    "    plt.imshow(player.permute(1, 2, 0).numpy())\n",
    "    plt.title(titles[i])  \n",
    "    plt.axis('off')      \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame8 = clip[:, 8, : , : , :] \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, player in enumerate(frame8):\n",
    "    plt.subplot(2, 6, i + 1)\n",
    "    plt.imshow(player.permute(1, 2, 0).numpy())\n",
    "    plt.title(titles[i])  \n",
    "    plt.axis('off')      \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Can return a full clip with sorted player crop with its group label (all the same) ((12, 9, crop frame), tensor(9,8)) *needed for B8*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** we sort player recored x-axis to separate each team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(224, 224),  \n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "data_loader = Group_Activity_DataSet(videos_path, annot_path, split=train_spilt, crops=True , seq=True, sort=True, labels=group_activity_labels, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip, label = data_loader[50]\n",
    "clip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = label[0].argmax().item() # group label at frist frame\n",
    "group_label = group_activity_clases[label_idex]\n",
    "print(f\"Group activity label: {group_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frist_frame = clip[:, 0, : , : , :] # take the frist frame\n",
    "\n",
    "titles = [f\"Player {i+1}\" for i in range(12)]  \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, player in enumerate(frist_frame[:6]): # take frist team\n",
    "    plt.subplot(1, 6, i + 1)\n",
    "    plt.imshow(player.permute(1, 2, 0).numpy())\n",
    "    plt.title(titles[i])  \n",
    "    plt.axis('off')      \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, player in enumerate(frist_frame[6:]): # take second team\n",
    "    plt.subplot(1, 6, i + 1)\n",
    "    plt.imshow(player.permute(1, 2, 0).numpy())\n",
    "    plt.title(titles[i + 6])  \n",
    "    plt.axis('off')      \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip, label = data_loader[600]\n",
    "label_idex = label[0].argmax().item() # group label at frist frame\n",
    "group_label = group_activity_clases[label_idex]\n",
    "\n",
    "print(f\"Group activity label: {group_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frist_frame = clip[:, 0, : , : , :] # take the frist frame\n",
    "\n",
    "titles = [f\"Player {i+1}\" for i in range(12)]  \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, player in enumerate(frist_frame[:6]): # take frist team\n",
    "    plt.subplot(1, 6, i + 1)\n",
    "    plt.imshow(player.permute(1, 2, 0).numpy())\n",
    "    plt.title(titles[i])  \n",
    "    plt.axis('off')      \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, player in enumerate(frist_frame[6:]): # take second team\n",
    "    plt.subplot(1, 6, i + 1)\n",
    "    plt.imshow(player.permute(1, 2, 0).numpy())\n",
    "    plt.title(titles[i + 6])  \n",
    "    plt.axis('off')      \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test hierarchical group activity dataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Can return crop of player in the same clip, each players label and group label of the clip ( (12, 9, crop frame), (12, 9, 9), (9,8) ) *needed for B9*.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "    A.Resize(224, 224),  \n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "data_loader = Hierarchical_Group_Activity_DataSet(\n",
    "    videos_path=videos_path,\n",
    "    annot_path=annot_path,\n",
    "    split=train_spilt,\n",
    "    labels=activities_labels,\n",
    "    transform=transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip, person_labels, group_labels = data_loader[600]\n",
    "clip.shape # (12, 9, 3, 224, 224) => 12 player, 9 frame, c, h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_labels.shape # (12, 9, 9) => each player at each frame label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_labels.shape # (9, 8) => group label at each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idex = group_labels[0].argmax().item() # group label at frist frame\n",
    "group_label = group_activity_clases[label_idex]\n",
    "print(f\"Group activity label: {group_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frist_frame = clip[:, 0, : , : , :] # take the frist frame\n",
    "\n",
    "titles = [f\"Player {i+1}\" for i in range(12)]  \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, player in enumerate(frist_frame[:6]): # take frist team\n",
    "\n",
    "    label_idex = person_labels[i, 0].argmax().item() # take label of the player at frist frame\n",
    "    player_label = people_activity_clases[label_idex]\n",
    "    \n",
    "    plt.subplot(1, 6, i + 1)\n",
    "    plt.imshow(player.permute(1, 2, 0).numpy())\n",
    "    plt.title(f\"{titles[i]} - label: {player_label}\")  \n",
    "    plt.axis('off')      \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, player in enumerate(frist_frame[6:]): # take second team\n",
    "    label_idex = person_labels[i, 0].argmax().item() # take label of the player at frist frame\n",
    "    player_label = people_activity_clases[label_idex]\n",
    "    \n",
    "    plt.subplot(1, 6, i + 1)\n",
    "    plt.imshow(player.permute(1, 2, 0).numpy())\n",
    "    plt.title(f\"{titles[i]} - label: {player_label}\") \n",
    "    plt.axis('off')      \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
