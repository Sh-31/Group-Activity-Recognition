# Baseline B4.yml

model:
  num_classes: 8 
  input_size: 2048 # this need be fixed
  hidden_size: 512
  num_layers: 1
  num_clases_label:  ["r_set", "r_spike" , "r-pass", "r_winpoint", "l_winpoint", "l-pass", "l-spike", "l_set"]

training:
  batch_size: 
    train: 16
    val: 32
  learning_rate: 0.0001 # 1e-4
  epochs: 35
  optimizer: "AdamW"
  weight_decay: 1 
  label_smoothing: 0.15 

data:
  dataset_name: "GroupActivityDataset"
  data_dir: "data"
  annot_path: "data/annot_all.pkl"
  videos_path: "data/videos"

  video_splits:
    train: [1, 3, 6, 7, 10, 13, 15, 16, 18, 22, 23, 31, 32, 36, 38, 39, 40, 41, 42, 48, 50, 52, 53, 54]
    validation: [0, 2, 8, 12, 17, 19, 24, 26, 27, 28, 30, 33, 46, 49, 51]
    test: [4, 5, 9, 11, 14, 20, 21, 25, 29, 34, 35, 37, 43, 44, 45, 47]

experiment:
  name: "Baseline_B4"
  version: 1
  seed: 31
  output_dir: "outputs"
  description: "Temporal model with image features level 
be  representation per clip use 9 frames 
per image then we have sequence for each clip of 9 steps 
train an LSTM on these sequences."
